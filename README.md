# R2DE

This is workshop in Road to data engineer class 2022


![image](https://user-images.githubusercontent.com/10781791/193826666-f99ac0bb-296d-41e1-9b44-d4473cea2272.png)


## Workshop 1: Getting Data from Different Sources

In this workshop, I learn how to retrieve data from databases and REST APIs. I use data from a database and a REST API as input and save the output as a CSV file.

## Workshop 2: Data Cleansing with Pandas and PySpark

In this workshop, I discover how to clean and preprocess data using Pandas and PySpark. I learn techniques to handle format errors, missing data, and outliers. The workshop covers data profiling and exploratory data analysis (EDA) as well.

## Workshop 3: Uploading Data to Datalake (Google Cloud Storage)

This workshop explores different methods to upload data to a datalake using Google Cloud Storage. I learn to upload data via the web UI, `gsutil` command, and Python code.

## Workshop 4: Automated Data Pipeline with Airflow

I learn about Apache Airflow, a workflow orchestration service, in this workshop. I create a DAG file and schedule it to automate the data pipeline.

## Workshop 5: Automating Data Uploads to Google BigQuery

In this workshop, I discover how to automate the pipeline for uploading data from a datalake to Google BigQuery. I learn various methods, including using the Cloud Console, bq command-line tool, and Airflow's operators.

## Workshop 6: Creating Dashboards with Looker Studio

I learn how to use data in Google BigQuery to create interactive dashboards using Looker Studio. I visualize and explore my data to gain insights.
